{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = full_clean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The goal of this project is to assess the potential of data��driven statistical methods for detecting and reducing coding differences between healthcare systems in Sentinel. Findings will inform development and deployment of methods and computational tools for transferring knowledge learned from one site to another and pave the way towards scalable and automated harmonization of electronic health records data.']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Use_Case_ID']== 'HHS-0076-2023']['Summary'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tech_edit\n",
       "Unspecified Machine Learning    247\n",
       "All Other Techniques            151\n",
       "Natural Language Processing     118\n",
       "Neural Network                   85\n",
       "Machine Vision                   55\n",
       "Other                            54\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tech_edit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tech_edit\n",
       "Unspecified Machine Learning    247\n",
       "Other                           174\n",
       "Natural Language Processing     118\n",
       "Neural Network                   85\n",
       "Machine Vision                   55\n",
       "Automation                       31\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tech_edit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Techniques</th>\n",
       "      <th>tech_edit</th>\n",
       "      <th>tech_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Land Use Plan Document and Data Mining and Ana...</td>\n",
       "      <td>Exploring the potential to identify patterns, ...</td>\n",
       "      <td>Natural Language Processing and Geo Classifica...</td>\n",
       "      <td>Natural Language Processing</td>\n",
       "      <td>Natural Language Processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Seasonal/Temporary Wetland/Floodplain Delineat...</td>\n",
       "      <td>Reclamation was interested in determining if r...</td>\n",
       "      <td>Image classification using Joint Unsupervised ...</td>\n",
       "      <td>Other</td>\n",
       "      <td>Classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Driven Sub-Seasonal Forecasting of Temper...</td>\n",
       "      <td>Reclamation has run 2, year-long prize competi...</td>\n",
       "      <td>Range of data driven, AI/ML techniques (e.g. r...</td>\n",
       "      <td>Other</td>\n",
       "      <td>Classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Driven Streamflow Forecasting</td>\n",
       "      <td>Reclamation, along with partners from the CEAT...</td>\n",
       "      <td>Range of data driven, AI/ML techniques (e.g. L...</td>\n",
       "      <td>Neural Network</td>\n",
       "      <td>Neural Network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Snowcast Showdown</td>\n",
       "      <td>Reclamation partnered with Bonneville Power Ad...</td>\n",
       "      <td>Range of data driven, AI/ML techniques</td>\n",
       "      <td>Unspecified Machine Learning</td>\n",
       "      <td>Unspecified Machine Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>Extraction of family medical history from pati...</td>\n",
       "      <td>This pilot project uses TIU documentation on A...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>VA /IRB approved research study for finding co...</td>\n",
       "      <td>This IRB approved research study uses  a rando...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>Interpretation/triage of eye images</td>\n",
       "      <td>Artificial intelligence supports triage of eye...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Machine Vision</td>\n",
       "      <td>Machine Vision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>Screening for esophageal adenocarcinoma</td>\n",
       "      <td>National VHA administrative data is used to ad...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>Social determinants of health extractor</td>\n",
       "      <td>AI is used with clinical notes to identify soc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unspecified Machine Learning</td>\n",
       "      <td>Unspecified Machine Learning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>710 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title  \\\n",
       "0    Land Use Plan Document and Data Mining and Ana...   \n",
       "1    Seasonal/Temporary Wetland/Floodplain Delineat...   \n",
       "2    Data Driven Sub-Seasonal Forecasting of Temper...   \n",
       "3                   Data Driven Streamflow Forecasting   \n",
       "4                                    Snowcast Showdown   \n",
       "..                                                 ...   \n",
       "705  Extraction of family medical history from pati...   \n",
       "706  VA /IRB approved research study for finding co...   \n",
       "707                Interpretation/triage of eye images   \n",
       "708            Screening for esophageal adenocarcinoma   \n",
       "709            Social determinants of health extractor   \n",
       "\n",
       "                                               Summary  \\\n",
       "0    Exploring the potential to identify patterns, ...   \n",
       "1    Reclamation was interested in determining if r...   \n",
       "2    Reclamation has run 2, year-long prize competi...   \n",
       "3    Reclamation, along with partners from the CEAT...   \n",
       "4    Reclamation partnered with Bonneville Power Ad...   \n",
       "..                                                 ...   \n",
       "705  This pilot project uses TIU documentation on A...   \n",
       "706  This IRB approved research study uses  a rando...   \n",
       "707  Artificial intelligence supports triage of eye...   \n",
       "708  National VHA administrative data is used to ad...   \n",
       "709  AI is used with clinical notes to identify soc...   \n",
       "\n",
       "                                            Techniques  \\\n",
       "0    Natural Language Processing and Geo Classifica...   \n",
       "1    Image classification using Joint Unsupervised ...   \n",
       "2    Range of data driven, AI/ML techniques (e.g. r...   \n",
       "3    Range of data driven, AI/ML techniques (e.g. L...   \n",
       "4               Range of data driven, AI/ML techniques   \n",
       "..                                                 ...   \n",
       "705                                                NaN   \n",
       "706                                                NaN   \n",
       "707                                                NaN   \n",
       "708                                                NaN   \n",
       "709                                                NaN   \n",
       "\n",
       "                        tech_edit                    tech_clean  \n",
       "0     Natural Language Processing   Natural Language Processing  \n",
       "1                           Other                Classification  \n",
       "2                           Other                Classification  \n",
       "3                  Neural Network                Neural Network  \n",
       "4    Unspecified Machine Learning  Unspecified Machine Learning  \n",
       "..                            ...                           ...  \n",
       "705                         Other                          None  \n",
       "706                         Other                          None  \n",
       "707                Machine Vision                Machine Vision  \n",
       "708                         Other                          None  \n",
       "709  Unspecified Machine Learning  Unspecified Machine Learning  \n",
       "\n",
       "[710 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[['Title', 'Summary', 'Techniques', 'tech_edit','tech_clean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('test.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"2023_ai_inventory_edit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vk/_03tl7qs1sv80_pgkhd8bxch0000gn/T/ipykernel_93319/1481991836.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  no_tech['tech_trySum'] = None\n"
     ]
    }
   ],
   "source": [
    "no_tech = data[data['Techniques'].isna()]\n",
    "no_tech['tech_trySum'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in other:\n",
    "    print(f\"\"\"<option value=\"{d}\">\n",
    "            {d} ({len(data[data['Department'] == d])})\n",
    "          </option>\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<option value=\"Classification\">\n",
      "            Classification (26)\n",
      "          </option>\n",
      "<option value=\"Regression\">\n",
      "            Regression (16)\n",
      "          </option>\n",
      "<option value=\"Other\">\n",
      "            Other (54)\n",
      "          </option>\n",
      "<option value=\"None\">\n",
      "            None (0)\n",
      "          </option>\n",
      "<option value=\"Large Language Model\">\n",
      "            Large Language Model (1)\n",
      "          </option>\n",
      "<option value=\"Automation\">\n",
      "            Automation (31)\n",
      "          </option>\n",
      "<option value=\"Time Series Forecast\">\n",
      "            Time Series Forecast (6)\n",
      "          </option>\n"
     ]
    }
   ],
   "source": [
    "top = df['tech_edit'].unique().tolist()\n",
    "\n",
    "other = [d for d in df['tech_clean'].unique().tolist() if d not in top]\n",
    "\n",
    "for d in other:\n",
    "    print(f\"\"\"<option value=\"{d}\">\n",
    "            {d} ({len(df[df['tech_clean'] == d])})\n",
    "          </option>\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_clean(export:bool = True):\n",
    "    data = pd.read_csv(\"2023_ai_inventory.csv\")\n",
    "    df_clean = process_data(data)\n",
    "\n",
    "    for col in ['dev_edit', 'tech_edit', 'dep_edit']:\n",
    "        df_clean = starting_grid(df_clean, col)\n",
    "        df_clean = split_grid(df_clean, col)\n",
    "\n",
    "    if export:\n",
    "        df_clean.to_csv('2023_ai_inventory_edit.csv', index=False)\n",
    "\n",
    "    return df_clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(df):\n",
    "\n",
    "    #clean up agency and Office\n",
    "    df['Agency'] = df['Agency'].fillna('No Agency Provided')\n",
    "    df['Office'] = df['Office'].fillna('No Office Provided')\n",
    "\n",
    "    #clean up summary\n",
    "    df['Summary'] = df['Summary'].str.replace(\"_x000D_\", \" \")\n",
    "    # clean up dev stage\n",
    "    # In Use\n",
    "    stages = {'In Use': ['Operation and Maintenance','In-use', 'Implementation', \n",
    "                     'Operation and Management','In mission', 'In production: more than 1 year', \n",
    "                     'In production: less than six months', 'Completed','In production: less than one year', 'Deployment', \n",
    "                     'Technical transfer of capability to industry planned this summer', 'In production: less than 6 months' ,\n",
    "                      'Technical transfer of capability to industry planned this summer.' , 'OPC runs in a pseudo-operational capacity via a webpage maintained by the Massachusetts Institute of Technology - Lincoln Lab, as well as in a test and evaluation capacity in a research mode.'],\n",
    "          'In Planning': ['Initiation', 'Planned (not in production)', 'Investigating/Proof of concept' ],\n",
    "          'In Development': ['Development and Acquisition', 'Development (not in production)', 'Proof-of-concept completed',\n",
    "                             'Currently under development', \"This is a pilot initiative\", \"User Acceptance Testing to begin early spring '22\",\n",
    "                               'Proof of Concept completed and published', 'Initial development', 'Refinments planned for future release', 'Successfully tested but not in production.'],\n",
    "          'No Development Stage Indicated': [np.nan]\n",
    "                }\n",
    "\n",
    "    # Initialize the new column with None or any default value\n",
    "    df['dev_edit'] = None\n",
    "\n",
    "    # Iterate through the dictionary and update the new column\n",
    "    for key, stage_list in stages.items():\n",
    "        df.loc[df['Development_Stage'].isin(stage_list), 'dev_edit'] = key\n",
    "\n",
    "    #clean up technique\n",
    "    nlp = ['nlp', 'natural language']\n",
    "    nn = ['neural network', 'nn', 'lstm', 'gans', 'synthetic']\n",
    "    gml = ['machine learning', 'ml', 'ai', 'artificial intelligence', \n",
    "        'reinforcement','doodler', 'transfer']\n",
    "    llm = ['large language']\n",
    "    mv = ['machine vision', 'computer vision']\n",
    "    reg = ['regression']\n",
    "    classifiers = ['classifier', 'forest', 'classification', 'identification']\n",
    "    ts = ['time series', 'forecasting']\n",
    "    auto = ['automation', 'automated', 'automating']\n",
    "    other = ['other', 'unknown', 'big data', 'automation', 'sql', 'visual', 'fuzzy']\n",
    "\n",
    "    options = [('Natural Language Processing', nlp),('Neural Network', nn),\n",
    "            ('Machine Vision',mv),('Regression', reg), ('Classification', classifiers),(\"Large Language Model\", llm),\n",
    "                ('Time Series Forecast', ts),(\"Automation\", auto), (\"Unspecified Machine Learning\", gml), ('Other', other)]\n",
    "    \n",
    "\n",
    "    def sort_by_techniques(technique):\n",
    "        if pd.isnull(technique):\n",
    "            return None\n",
    "        for cat, list in options:\n",
    "            if technique is not None:\n",
    "                if any(match in technique.lower() for match in list):\n",
    "                    return cat\n",
    "        \n",
    "        return 'review'\n",
    "    \n",
    "     #clean up technique\n",
    "    nlp2 = ['nlp', 'natural language']\n",
    "    nn2 = ['neural network', 'lstm']\n",
    "    gml2 = ['machine learning', 'ml', 'ai', 'artificial intelligence', \n",
    "        'reinforcement']\n",
    "    llm2 = ['large language']\n",
    "    mv2 = ['machine vision', 'computer vision', \"image\"]\n",
    "    reg2 = ['regression']\n",
    "    classifiers2 = ['classifier', 'forest', 'classification']\n",
    "    ts2 = ['time series', 'forecasting']\n",
    "    auto2 = ['automation', 'automated', 'automating']\n",
    "    other2 = ['big data', 'automation']\n",
    "\n",
    "    options2 = [('Natural Language Processing', nlp2),('Neural Network', nn2),\n",
    "            ('Machine Vision',mv2),('Regression', reg2), ('Classification', classifiers2),(\"Large Language Model\", llm2),\n",
    "                ('Time Series Forecast', ts2),(\"Automation\", auto), (\"Unspecified Machine Learning\", gml2), ('Other', other2)]\n",
    "    \n",
    "    def sort_by(df):\n",
    "        for cat, list in options2:\n",
    "            if df['tech_stg2'] is None:\n",
    "                if any(match in df['Summary'].lower() for match in list):\n",
    "                    return cat\n",
    "\n",
    "   \n",
    "    \n",
    "    df['tech_stg1'] = df['Techniques'].apply(lambda x: sort_by_techniques(x))\n",
    "\n",
    "    df['tech_stg2'] = None\n",
    "    df['tech_stg2'] = df.apply(sort_by, axis=1)\n",
    "\n",
    "    df['tech_clean'] = df['tech_stg1'].combine_first(df['tech_stg2'])\n",
    "\n",
    "    \n",
    "\n",
    "    top5_tech  = df.groupby('tech_clean')['Use_Case_ID'].count().sort_values(ascending=False).head(5).reset_index()['tech_clean'].tolist()\n",
    "    df['tech_edit'] = df['tech_clean'].apply(lambda x: x if x in top5_tech else 'All Other Techniques')\n",
    "\n",
    "    df['tech_edit'] = np.where(df['tech_edit'] == 'Other', 'All Other Techniques', df['tech_edit'])\n",
    "\n",
    "\n",
    "    # clean up department\n",
    "    top5_dep  = df.groupby('Department')['Use_Case_ID'].count().sort_values(ascending=False).head(5).reset_index()['Department'].tolist()\n",
    "    df['dep_edit'] = df['Department'].apply(lambda x: x if x in top5_dep else 'All Other Departments')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_chart_xy(df, col, col_count):\n",
    "    \n",
    "    dict = {}\n",
    "    # for now\n",
    "    \n",
    "    values = df[col].unique().tolist()\n",
    "    values.sort()\n",
    "    # 5 wide means first is at 3 then +5\n",
    "    i = 0\n",
    "    for v in values:\n",
    "        dict[v] = i\n",
    "        i += 1\n",
    "\n",
    "    df['rn'] = df.sort_values([col,'Use_Case_ID'], ascending=[True,True]) \\\n",
    "             .groupby([col]) \\\n",
    "             .cumcount()\n",
    "    df['x'] = (df[col].map(dict) * 7) + (df['rn'] % col_count) +1\n",
    "    df['y'] = df['rn'] // col_count + 1\n",
    "\n",
    "    x_name = col + '_x'\n",
    "    y_name = col + '_y'\n",
    "    df = df.rename(columns={'x': x_name, 'y': y_name})\n",
    "    df.drop(columns=['rn'], inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def create_orderd_cats(df, col):\n",
    "    cats = df.groupby(col)['Use_Case_ID'].count().reset_index().sort_values('Use_Case_ID', ascending=False)[col].to_list()\n",
    "\n",
    "    # put others first\n",
    "    if 'Development' in cats:\n",
    "        cats.remove('No Development Stage Indicated')\n",
    "        cats.insert(0, 'No Development Stage Indicated')\n",
    "    elif \"All Other Techniques\" in cats:\n",
    "        cats.remove('All Other Techniques')\n",
    "        cats.insert(0, 'All Other Techniques')\n",
    "    \n",
    "    return cats\n",
    "    \n",
    "def starting_grid(df, start_col, max_x = 27):\n",
    "\n",
    "    if start_col == 'dev_edit':\n",
    "        c = 'dev'\n",
    "\n",
    "    elif start_col == 'tech_edit':\n",
    "        c = 't'\n",
    "    elif start_col == 'dep_edit':\n",
    "        c = 'dep'\n",
    "    \n",
    "    \n",
    "    col = f\"start_{c}\"\n",
    "    x_name = col + '_x'\n",
    "    y_name = col + '_y'\n",
    "\n",
    "    #TODO\n",
    "\n",
    "    ordered_cats = create_orderd_cats(df, start_col)\n",
    "\n",
    "    df[start_col] = pd.Categorical(df[start_col], ordered=True, \n",
    "                              categories=ordered_cats)\n",
    "        \n",
    "    df = df.sort_values([start_col, 'Use_Case_ID']).reset_index(drop=True) \n",
    "\n",
    "\n",
    "    df['rn'] = df.index\n",
    "\n",
    "    df[x_name] = df['rn'] % max_x + 1\n",
    "    df[y_name] = df['rn'] // max_x + 1\n",
    " \n",
    "    return df \n",
    "\n",
    "def split_grid(df, split_col, max_x = 27, max_y=27 ):\n",
    "\n",
    "    if split_col == 'dev_edit':\n",
    "        c = 'dev'\n",
    "    elif split_col == 'tech_edit':\n",
    "        c = 't'\n",
    "    elif split_col == 'dep_edit':\n",
    "        c = 'dep'\n",
    "    \n",
    "    \n",
    "    col = f\"split_{c}\"\n",
    "\n",
    "    #df = df.sort_values([split_col, 'Use_Case_ID']).reset_index(drop=True) \n",
    "\n",
    "    # df['rn'] = df.index \n",
    "    x_name = col + '_x'\n",
    "    y_name = col + '_y'\n",
    "\n",
    "    df[x_name] = df['rn'] % max_x + 1\n",
    "\n",
    "    dict = {}\n",
    "    i = 0\n",
    "    for val in df[split_col].unique():\n",
    "        dict[val] = i\n",
    "        i += 3\n",
    "        \n",
    "    df[y_name] = df.apply(lambda x: x['rn'] // max_y + 1 + dict[x[split_col]], axis=1)\n",
    "  \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 710 models\n",
    "* every model has a unique case id and department code (should use department)\n",
    "* \n",
    "* 10% are missing agency. adding new col for chart to just replace with department name\n",
    "    * Departments either have agency or dont (HUD, Labor, Treasury, VA, and EPA have no agency info)\n",
    "* Only Agriculture and Health and Human Services have office info\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Use_Case_ID           0.000000\n",
       "Department_Code       0.000000\n",
       "Agency               10.704225\n",
       "Office               72.394366\n",
       "Title                 0.000000\n",
       "Summary               0.000000\n",
       "Development_Stage    45.211268\n",
       "Techniques           55.633803\n",
       "Source_Code          97.605634\n",
       "Department            0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data.isnull().sum() / len(data)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Fluid migration from well-to-well communication will be inputted in AI to determine a costs-benefit analysis</td>\n",
       "      <td>This project will develop an ML algorithm to predict the time when a \\ngrowing fracture will reach the monitored well. The ML workflow will be \\ntrained on the distinctive tensile strain signature that precedes the \\ngrowing fracture. The new workflow will be designed to work in \\nconjunction with the fracture warning ML workflow developed in EY21. \\nTogether, these workflows will: (1) provide an early warning of well-to-\\nwell communication, (2) predict the measured depths where the \\ncommunication will happen, and (3) provide an estimated time until the \\nbeginning of well-to-well communication.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>To drive insights on the dependencies between the natural gas and electricity sectors to increase reliability of the NG system</td>\n",
       "      <td>Commercially available models will be used to generate predictive \\nscenarios</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>To drive insights on the power system reliability, cost, and operations during the energy transition with and without FECM technologies</td>\n",
       "      <td>Commercially available models will be used to generate predictive \\nscenarios</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>Using recursive neural networks and using fiber optic cables to recognize strain patterns and warn operators a fracture is coming.</td>\n",
       "      <td>This project will develop an ML algorithm to predict the time when a \\ngrowing fracture will reach the monitored well. The ML workflow will be \\ntrained on the distinctive tensile strain signature that precedes the \\ngrowing fracture. The new workflow will be designed to work in \\nconjunction with the fracture warning ML workflow developed in EY21. \\nTogether, these workflows will: (1) provide an early warning of well-to-\\nwell communication, (2) predict the measured depths where the \\ncommunication will happen, and (3) provide an estimated time until the \\nbeginning of well-to-well communication.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>Form Recognizer for Benefits Forms</td>\n",
       "      <td>Custom machine learning model to extract data from complex forms to tag data entries to field headers. The input is a document or scanned image of the form and the output is a JSON response with key/value pairs extracted by running the form against the custom trained model.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>Data Ingestion of Payroll Forms</td>\n",
       "      <td>Custom machine learning model to extract data from complex forms to tag data entries to field headers. The input is a document or scanned image of the form and the output is a JSON response with key/value pairs extracted by running the form against the custom trained model.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>R+2:18eDIRECT: Clarivate</td>\n",
       "      <td>AI to identify drug repurposing candidates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>ReDIRECT: AriScience</td>\n",
       "      <td>AI to identify drug repurposing candidates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>Machine learning models to predict disease progression among veterans with hepatitis C virus</td>\n",
       "      <td>A machine learning model is used to predict disease progression among veterans with hepatitis C virus.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>Reinforcement learning evaluation of treatment policies for patients with hepatitis C virus</td>\n",
       "      <td>A machine learning model is used to predict disease progression among veterans with hepatitis C virus.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                       Title  \\\n",
       "140                             Fluid migration from well-to-well communication will be inputted in AI to determine a costs-benefit analysis   \n",
       "159           To drive insights on the dependencies between the natural gas and electricity sectors to increase reliability of the NG system   \n",
       "160  To drive insights on the power system reliability, cost, and operations during the energy transition with and without FECM technologies   \n",
       "243       Using recursive neural networks and using fiber optic cables to recognize strain patterns and warn operators a fracture is coming.   \n",
       "310                                                                                                       Form Recognizer for Benefits Forms   \n",
       "316                                                                                                          Data Ingestion of Payroll Forms   \n",
       "392                                                                                                                 R+2:18eDIRECT: Clarivate   \n",
       "393                                                                                                                     ReDIRECT: AriScience   \n",
       "696                                             Machine learning models to predict disease progression among veterans with hepatitis C virus   \n",
       "701                                              Reinforcement learning evaluation of treatment policies for patients with hepatitis C virus   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Summary  \n",
       "140  This project will develop an ML algorithm to predict the time when a \\ngrowing fracture will reach the monitored well. The ML workflow will be \\ntrained on the distinctive tensile strain signature that precedes the \\ngrowing fracture. The new workflow will be designed to work in \\nconjunction with the fracture warning ML workflow developed in EY21. \\nTogether, these workflows will: (1) provide an early warning of well-to-\\nwell communication, (2) predict the measured depths where the \\ncommunication will happen, and (3) provide an estimated time until the \\nbeginning of well-to-well communication.  \n",
       "159                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Commercially available models will be used to generate predictive \\nscenarios  \n",
       "160                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Commercially available models will be used to generate predictive \\nscenarios  \n",
       "243  This project will develop an ML algorithm to predict the time when a \\ngrowing fracture will reach the monitored well. The ML workflow will be \\ntrained on the distinctive tensile strain signature that precedes the \\ngrowing fracture. The new workflow will be designed to work in \\nconjunction with the fracture warning ML workflow developed in EY21. \\nTogether, these workflows will: (1) provide an early warning of well-to-\\nwell communication, (2) predict the measured depths where the \\ncommunication will happen, and (3) provide an estimated time until the \\nbeginning of well-to-well communication.  \n",
       "310                                                                                                                                                                                                                                                                                                                                            Custom machine learning model to extract data from complex forms to tag data entries to field headers. The input is a document or scanned image of the form and the output is a JSON response with key/value pairs extracted by running the form against the custom trained model.  \n",
       "316                                                                                                                                                                                                                                                                                                                                            Custom machine learning model to extract data from complex forms to tag data entries to field headers. The input is a document or scanned image of the form and the output is a JSON response with key/value pairs extracted by running the form against the custom trained model.  \n",
       "392                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    AI to identify drug repurposing candidates  \n",
       "393                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    AI to identify drug repurposing candidates  \n",
       "696                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        A machine learning model is used to predict disease progression among veterans with hepatitis C virus.  \n",
       "701                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        A machine learning model is used to predict disease progression among veterans with hepatitis C virus.  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "data[data.duplicated('Summary', keep=False)][[\"Title\", \"Summary\"]]\n",
    "\n",
    "# exact duplicates?\n",
    "#these look to be different use cases, so we'll keep them all\n",
    "#data[data['Use_Case_ID'].isin(['DOC-0024-2023', 'DOC-0025-2023'])]['Summary'].values\n",
    "\n",
    "#data[data['Use_Case_ID'].isin(['DOT-0007-2023', 'DOT-0008-2023'])]['Summary'].values\n",
    "\n",
    "#data[data['Use_Case_ID'].isin(['HHS-0006-2023', 'HHS-0007-2023'])]['Summary'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Department\n",
       "Department of Agriculture                          0.0\n",
       "Department of Commerce                             0.0\n",
       "Department of Education                            0.0\n",
       "Department of Energy                               0.0\n",
       "Department of Health and Human Services            0.0\n",
       "Department of Homeland Security                    0.0\n",
       "Department of Housing and Urban Development      100.0\n",
       "Department of Interior                             0.0\n",
       "Department of Justice                              0.0\n",
       "Department of Labor                              100.0\n",
       "Department of State                                0.0\n",
       "Department of Transportation                       0.0\n",
       "Department of Treasury                           100.0\n",
       "Department of Veterans Affairs                   100.0\n",
       "National Aeronautics and Space Administration      0.0\n",
       "National Archives and Records Administration       0.0\n",
       "Social Security Administration                     0.0\n",
       "U.S. Agency for International Development          0.0\n",
       "U.S. Environmental Protection Agency             100.0\n",
       "U.S. General Services Administration               0.0\n",
       "U.S. Office of Personnel Management                0.0\n",
       "Name: Agency, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#which department has the most missing agency data\n",
    "(data.groupby('Department')['Agency'].apply(lambda x: (x.isnull().sum() / len(x)) * 100))\n",
    "#(data.groupby('Department')['Office'].apply(lambda x: (x.isnull().sum() / len(x)) * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Use_Case_ID</th>\n",
       "      <th>Department_Code</th>\n",
       "      <th>Agency</th>\n",
       "      <th>Office</th>\n",
       "      <th>Title</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Development_Stage</th>\n",
       "      <th>Techniques</th>\n",
       "      <th>Source_Code</th>\n",
       "      <th>Department</th>\n",
       "      <th>...</th>\n",
       "      <th>split_dev_x</th>\n",
       "      <th>split_dev_y</th>\n",
       "      <th>start_t_x</th>\n",
       "      <th>start_t_y</th>\n",
       "      <th>split_t_x</th>\n",
       "      <th>split_t_y</th>\n",
       "      <th>start_dep_x</th>\n",
       "      <th>start_dep_y</th>\n",
       "      <th>split_dep_x</th>\n",
       "      <th>split_dep_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DOI-0000-2023</td>\n",
       "      <td>DOI</td>\n",
       "      <td>BLM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Land Use Plan Document and Data Mining and Ana...</td>\n",
       "      <td>Exploring the potential to identify patterns, ...</td>\n",
       "      <td>Planned (not in production)</td>\n",
       "      <td>Natural Language Processing and Geo Classifica...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Department of Interior</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>33</td>\n",
       "      <td>24</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DOI-0001-2023</td>\n",
       "      <td>DOI</td>\n",
       "      <td>BOR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Seasonal/Temporary Wetland/Floodplain Delineat...</td>\n",
       "      <td>Reclamation was interested in determining if r...</td>\n",
       "      <td>Completed</td>\n",
       "      <td>Image classification using Joint Unsupervised ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Department of Interior</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DOI-0002-2023</td>\n",
       "      <td>DOI</td>\n",
       "      <td>BOR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Driven Sub-Seasonal Forecasting of Temper...</td>\n",
       "      <td>Reclamation has run 2, year-long prize competi...</td>\n",
       "      <td>Development (not in production)</td>\n",
       "      <td>Range of data driven, AI/ML techniques (e.g. r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Department of Interior</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DOI-0003-2023</td>\n",
       "      <td>DOI</td>\n",
       "      <td>BOR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Driven Streamflow Forecasting</td>\n",
       "      <td>Reclamation, along with partners from the CEAT...</td>\n",
       "      <td>Development (not in production)</td>\n",
       "      <td>Range of data driven, AI/ML techniques (e.g. L...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Department of Interior</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DOI-0004-2023</td>\n",
       "      <td>DOI</td>\n",
       "      <td>BOR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Snowcast Showdown</td>\n",
       "      <td>Reclamation partnered with Bonneville Power Ad...</td>\n",
       "      <td>Development and Acquisition</td>\n",
       "      <td>Range of data driven, AI/ML techniques</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Department of Interior</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>VA-0035-2023</td>\n",
       "      <td>VA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Extraction of family medical history from pati...</td>\n",
       "      <td>This pilot project uses TIU documentation on A...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Department of Veterans Affairs</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>VA-0036-2023</td>\n",
       "      <td>VA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VA /IRB approved research study for finding co...</td>\n",
       "      <td>This IRB approved research study uses  a rando...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Department of Veterans Affairs</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>VA-0037-2023</td>\n",
       "      <td>VA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Interpretation/triage of eye images</td>\n",
       "      <td>Artificial intelligence supports triage of eye...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Department of Veterans Affairs</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>8</td>\n",
       "      <td>39</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>VA-0038-2023</td>\n",
       "      <td>VA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Screening for esophageal adenocarcinoma</td>\n",
       "      <td>National VHA administrative data is used to ad...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Department of Veterans Affairs</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>VA-0039-2023</td>\n",
       "      <td>VA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Social determinants of health extractor</td>\n",
       "      <td>AI is used with clinical notes to identify soc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Department of Veterans Affairs</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>710 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Use_Case_ID Department_Code Agency Office  \\\n",
       "0    DOI-0000-2023             DOI    BLM    NaN   \n",
       "1    DOI-0001-2023             DOI    BOR    NaN   \n",
       "2    DOI-0002-2023             DOI    BOR    NaN   \n",
       "3    DOI-0003-2023             DOI    BOR    NaN   \n",
       "4    DOI-0004-2023             DOI    BOR    NaN   \n",
       "..             ...             ...    ...    ...   \n",
       "705   VA-0035-2023              VA    NaN    NaN   \n",
       "706   VA-0036-2023              VA    NaN    NaN   \n",
       "707   VA-0037-2023              VA    NaN    NaN   \n",
       "708   VA-0038-2023              VA    NaN    NaN   \n",
       "709   VA-0039-2023              VA    NaN    NaN   \n",
       "\n",
       "                                                 Title  \\\n",
       "0    Land Use Plan Document and Data Mining and Ana...   \n",
       "1    Seasonal/Temporary Wetland/Floodplain Delineat...   \n",
       "2    Data Driven Sub-Seasonal Forecasting of Temper...   \n",
       "3                   Data Driven Streamflow Forecasting   \n",
       "4                                    Snowcast Showdown   \n",
       "..                                                 ...   \n",
       "705  Extraction of family medical history from pati...   \n",
       "706  VA /IRB approved research study for finding co...   \n",
       "707                Interpretation/triage of eye images   \n",
       "708            Screening for esophageal adenocarcinoma   \n",
       "709            Social determinants of health extractor   \n",
       "\n",
       "                                               Summary  \\\n",
       "0    Exploring the potential to identify patterns, ...   \n",
       "1    Reclamation was interested in determining if r...   \n",
       "2    Reclamation has run 2, year-long prize competi...   \n",
       "3    Reclamation, along with partners from the CEAT...   \n",
       "4    Reclamation partnered with Bonneville Power Ad...   \n",
       "..                                                 ...   \n",
       "705  This pilot project uses TIU documentation on A...   \n",
       "706  This IRB approved research study uses  a rando...   \n",
       "707  Artificial intelligence supports triage of eye...   \n",
       "708  National VHA administrative data is used to ad...   \n",
       "709  AI is used with clinical notes to identify soc...   \n",
       "\n",
       "                   Development_Stage  \\\n",
       "0        Planned (not in production)   \n",
       "1                          Completed   \n",
       "2    Development (not in production)   \n",
       "3    Development (not in production)   \n",
       "4        Development and Acquisition   \n",
       "..                               ...   \n",
       "705                              NaN   \n",
       "706                              NaN   \n",
       "707                              NaN   \n",
       "708                              NaN   \n",
       "709                              NaN   \n",
       "\n",
       "                                            Techniques Source_Code  \\\n",
       "0    Natural Language Processing and Geo Classifica...         NaN   \n",
       "1    Image classification using Joint Unsupervised ...         NaN   \n",
       "2    Range of data driven, AI/ML techniques (e.g. r...         NaN   \n",
       "3    Range of data driven, AI/ML techniques (e.g. L...         NaN   \n",
       "4               Range of data driven, AI/ML techniques         NaN   \n",
       "..                                                 ...         ...   \n",
       "705                                                NaN         NaN   \n",
       "706                                                NaN         NaN   \n",
       "707                                                NaN         NaN   \n",
       "708                                                NaN         NaN   \n",
       "709                                                NaN         NaN   \n",
       "\n",
       "                         Department  ... split_dev_x split_dev_y start_t_x  \\\n",
       "0            Department of Interior  ...          19          33        24   \n",
       "1            Department of Interior  ...          17          16        13   \n",
       "2            Department of Interior  ...           5          27        14   \n",
       "3            Department of Interior  ...           6          27        21   \n",
       "4            Department of Interior  ...           7          27        15   \n",
       "..                              ...  ...         ...         ...       ...   \n",
       "705  Department of Veterans Affairs  ...          20          12        14   \n",
       "706  Department of Veterans Affairs  ...          21          12        15   \n",
       "707  Department of Veterans Affairs  ...          22          12         8   \n",
       "708  Department of Veterans Affairs  ...          23          12        16   \n",
       "709  Department of Veterans Affairs  ...          24          12        20   \n",
       "\n",
       "    start_t_y split_t_x split_t_y  start_dep_x  start_dep_y  split_dep_x  \\\n",
       "0          18        24        24            1            1            1   \n",
       "1           4        13         4            2            1            2   \n",
       "2           4        14         4            3            1            3   \n",
       "3          23        21        32            4            1            4   \n",
       "4          11        15        14            5            1            5   \n",
       "..        ...       ...       ...          ...          ...          ...   \n",
       "705         8        14         8            4           27            4   \n",
       "706         8        15         8            5           27            5   \n",
       "707        27         8        39            6           27            6   \n",
       "708         8        16         8            7           27            7   \n",
       "709        17        20        20            8           27            8   \n",
       "\n",
       "     split_dep_y  \n",
       "0              1  \n",
       "1              1  \n",
       "2              1  \n",
       "3              1  \n",
       "4              1  \n",
       "..           ...  \n",
       "705           42  \n",
       "706           42  \n",
       "707           42  \n",
       "708           42  \n",
       "709           42  \n",
       "\n",
       "[710 rows x 29 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Department\n",
       "Department of Agriculture                          0.000000\n",
       "Department of Commerce                           100.000000\n",
       "Department of Education                          100.000000\n",
       "Department of Energy                              99.438202\n",
       "Department of Health and Human Services            0.000000\n",
       "Department of Homeland Security                    0.000000\n",
       "Department of Housing and Urban Development      100.000000\n",
       "Department of Interior                             0.000000\n",
       "Department of Justice                              0.000000\n",
       "Department of Labor                                0.000000\n",
       "Department of State                              100.000000\n",
       "Department of Transportation                      35.714286\n",
       "Department of Treasury                             0.000000\n",
       "Department of Veterans Affairs                   100.000000\n",
       "National Aeronautics and Space Administration      0.000000\n",
       "National Archives and Records Administration       0.000000\n",
       "Social Security Administration                   100.000000\n",
       "U.S. Agency for International Development          0.000000\n",
       "U.S. Environmental Protection Agency             100.000000\n",
       "U.S. General Services Administration               0.000000\n",
       "U.S. Office of Personnel Management                0.000000\n",
       "Name: Development_Stage, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.groupby('Department')['Development_Stage'].apply(lambda x: (x.isnull().sum() / len(x)) * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Office\n",
       "ACF Children's Bureau                                                                            1\n",
       "AHRQ                                                                                             2\n",
       "BARDA (CBRN & DRIVe)                                                                             2\n",
       "BARDA (CBRN)                                                                                     4\n",
       "BARDA (DRIVe)                                                                                    5\n",
       "CBER/OBPV/DABRA                                                                                  3\n",
       "CDER/Office of Generic Drugs                                                                     4\n",
       "CDER/Office of New Drugs                                                                         1\n",
       "CDER/Office of Pharmaceutical Quality (OPQ)                                                      1\n",
       "CDER/Office of Strategic Programs (OSP)                                                          1\n",
       "CDER/Office of Surveillance and Epidemiology (OSE)                                              11\n",
       "CDER/Office of Translational Sciences                                                            1\n",
       "CDER/Office of Translational Sciences/Office of Biostatistics                                    2\n",
       "CDER/Office of Translational Sciences/Office of Clinical Pharmacology                            1\n",
       "CFSAN /OFAS                                                                                      1\n",
       "CFSAN/OFAS                                                                                       2\n",
       "CSELS                                                                                            3\n",
       "CTP/OS/DRSI                                                                                      3\n",
       "CVM                                                                                              1\n",
       "Centers for Medicare & Medicaid Services (CMS)                                                  23\n",
       "Chief Data Officer                                                                               1\n",
       "NCCDPHP/DDT                                                                                      1\n",
       "NCCDPHP/DNPAO                                                                                    4\n",
       "NCEZID                                                                                           1\n",
       "NCHS                                                                                             8\n",
       "NCIPC/DIP                                                                                        1\n",
       "NCIRD                                                                                            1\n",
       "NCTR                                                                                            12\n",
       "National Institutes of Health (NIH) CC                                                           1\n",
       "National Institutes of Health (NIH) CSR                                                          1\n",
       "National Institutes of Health (NIH) NCI                                                          1\n",
       "National Institutes of Health (NIH) NHLBI                                                        1\n",
       "National Institutes of Health (NIH) NIAID                                                        5\n",
       "National Institutes of Health (NIH) NIDCR                                                        2\n",
       "National Institutes of Health (NIH) NIEHS                                                        3\n",
       "National Institutes of Health (NIH) NIGMS                                                        4\n",
       "National Institutes of Health (NIH) NLM                                                         14\n",
       "National Institutes of Health (NIH) OD/DPCPSI/OAR                                                1\n",
       "National Institutes of Health (NIH) OD/DPCPSI/OPA                                                6\n",
       "National Institutes of Health (NIH) OD/OER                                                       3\n",
       "National Institutes of Health (NIH) OD/ORF                                                       5\n",
       "OIG                                                                                              2\n",
       "Office of Critical Infrastructure                                                                1\n",
       "Office of Information Management, Data and Analytics                                             1\n",
       "Office of Information Management, Data and Analytics/Division of Supply Chain Control Tower      1\n",
       "Office of Information Management, Data, and Analytics/Division of Modeling and Simulation        1\n",
       "Office of Information Management, Data, and Analytics/Division of Supply Chain Control Tower     1\n",
       "Office of Information Management, Data, and Analytics/ODA                                        2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"Department\"] == 'Department of Health and Human Services'].groupby(\"Office\", dropna=False).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use_Case_ID\n",
      "DHS-0000-2023    1\n",
      "HHS-0055-2023    1\n",
      "HHS-0079-2023    1\n",
      "HHS-0080-2023    1\n",
      "HHS-0081-2023    1\n",
      "dtype: int64\n",
      "Department_Code\n",
      "DOE    178\n",
      "HHS    157\n",
      "DOC     49\n",
      "DHS     41\n",
      "VA      40\n",
      "dtype: int64\n",
      "Agency\n",
      "National Energy Technology Laboratory    127\n",
      "NaN                                       76\n",
      "NIH                                       47\n",
      "FDA                                       44\n",
      "USDA                                      39\n",
      "dtype: int64\n",
      "Office\n",
      "NaN                                                   514\n",
      "Centers for Medicare & Medicaid Services (CMS)         23\n",
      "National Institutes of Health (NIH) NLM                14\n",
      "NCTR                                                   12\n",
      "CDER/Office of Surveillance and Epidemiology (OSE)     11\n",
      "dtype: int64\n",
      "Title\n",
      "Machine Learning for Occupant Safety Research    2\n",
      "Burn & Blast MCMs: Philips                       2\n",
      "First Guess Excessive Rainfall Outlook           2\n",
      "PyForecast                                       1\n",
      "Privileged Material Identification               1\n",
      "dtype: int64\n",
      "Summary\n",
      "A machine learning model is used to predict disease progression among veterans with hepatitis C virus.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          2\n",
      "Commercially available models will be used to generate predictive \\nscenarios                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   2\n",
      "Custom machine learning model to extract data from complex forms to tag data entries to field headers. The input is a document or scanned image of the form and the output is a JSON response with key/value pairs extracted by running the form against the custom trained model.                                                                                                                                                                                                                                                                                                                                              2\n",
      "AI to identify drug repurposing candidates                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      2\n",
      "This project will develop an ML algorithm to predict the time when a \\ngrowing fracture will reach the monitored well. The ML workflow will be \\ntrained on the distinctive tensile strain signature that precedes the \\ngrowing fracture. The new workflow will be designed to work in \\nconjunction with the fracture warning ML workflow developed in EY21. \\nTogether, these workflows will: (1) provide an early warning of well-to-\\nwell communication, (2) predict the measured depths where the \\ncommunication will happen, and (3) provide an estimated time until the \\nbeginning of well-to-well communication.    2\n",
      "dtype: int64\n",
      "Development_Stage\n",
      "NaN                            321\n",
      "Operation and Maintenance       91\n",
      "Development and Acquisition     81\n",
      "Initiation                      74\n",
      "Implementation                  50\n",
      "dtype: int64\n",
      "Techniques\n",
      "NaN                                395\n",
      "Other                               31\n",
      "Machine Learning                    30\n",
      "Artificial Intelligence Unknown     26\n",
      "Big Data, Other                     14\n",
      "dtype: int64\n",
      "Source_Code\n",
      "NaN                                                                                                                               693\n",
      "https://cran.r-project.org/web/packages/randomForest/randomForest.pdf<br>https://cran.r-project.org/web/packages/clhs/clhs.pdf      1\n",
      "https://www.sciencedirect.com/science/article/pii/S221242092100501X                                                                 1\n",
      "https://ntrs.nasa.gov/citations/20220010955                                                                                         1\n",
      "https://gitlab.grc.nasa.gov/zyahn/titan-clouds-project                                                                              1\n",
      "dtype: int64\n",
      "Department\n",
      "Department of Energy                       178\n",
      "Department of Health and Human Services    157\n",
      "Department of Commerce                      49\n",
      "Department of Homeland Security             41\n",
      "Department of Veterans Affairs              40\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for col in data.columns:\n",
    "    print(data.groupby(col, dropna=False).size().sort_values(ascending=False, na_position='first').head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
