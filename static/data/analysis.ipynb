{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_clean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Use_Case_ID</th>\n",
       "      <th>Department_Code</th>\n",
       "      <th>Agency</th>\n",
       "      <th>Office</th>\n",
       "      <th>Title</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Development_Stage</th>\n",
       "      <th>Techniques</th>\n",
       "      <th>Source_Code</th>\n",
       "      <th>Department</th>\n",
       "      <th>...</th>\n",
       "      <th>split_dev_x</th>\n",
       "      <th>split_dev_y</th>\n",
       "      <th>start_t_x</th>\n",
       "      <th>start_t_y</th>\n",
       "      <th>split_t_x</th>\n",
       "      <th>split_t_y</th>\n",
       "      <th>start_dep_x</th>\n",
       "      <th>start_dep_y</th>\n",
       "      <th>split_dep_x</th>\n",
       "      <th>split_dep_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DOI-0000-2023</td>\n",
       "      <td>DOI</td>\n",
       "      <td>BLM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Land Use Plan Document and Data Mining and Ana...</td>\n",
       "      <td>Exploring the potential to identify patterns, ...</td>\n",
       "      <td>Planned (not in production)</td>\n",
       "      <td>Natural Language Processing and Geo Classifica...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Department of Interior</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>33</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DOI-0001-2023</td>\n",
       "      <td>DOI</td>\n",
       "      <td>BOR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Seasonal/Temporary Wetland/Floodplain Delineat...</td>\n",
       "      <td>Reclamation was interested in determining if r...</td>\n",
       "      <td>Completed</td>\n",
       "      <td>Image classification using Joint Unsupervised ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Department of Interior</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DOI-0002-2023</td>\n",
       "      <td>DOI</td>\n",
       "      <td>BOR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Driven Sub-Seasonal Forecasting of Temper...</td>\n",
       "      <td>Reclamation has run 2, year-long prize competi...</td>\n",
       "      <td>Development (not in production)</td>\n",
       "      <td>Range of data driven, AI/ML techniques (e.g. r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Department of Interior</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DOI-0003-2023</td>\n",
       "      <td>DOI</td>\n",
       "      <td>BOR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Driven Streamflow Forecasting</td>\n",
       "      <td>Reclamation, along with partners from the CEAT...</td>\n",
       "      <td>Development (not in production)</td>\n",
       "      <td>Range of data driven, AI/ML techniques (e.g. L...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Department of Interior</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>24</td>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DOI-0004-2023</td>\n",
       "      <td>DOI</td>\n",
       "      <td>BOR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Snowcast Showdown</td>\n",
       "      <td>Reclamation partnered with Bonneville Power Ad...</td>\n",
       "      <td>Development and Acquisition</td>\n",
       "      <td>Range of data driven, AI/ML techniques</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Department of Interior</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>21</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>VA-0035-2023</td>\n",
       "      <td>VA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Extraction of family medical history from pati...</td>\n",
       "      <td>This pilot project uses TIU documentation on A...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Department of Veterans Affairs</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>VA-0036-2023</td>\n",
       "      <td>VA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VA /IRB approved research study for finding co...</td>\n",
       "      <td>This IRB approved research study uses  a rando...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Department of Veterans Affairs</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>VA-0037-2023</td>\n",
       "      <td>VA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Interpretation/triage of eye images</td>\n",
       "      <td>Artificial intelligence supports triage of eye...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Department of Veterans Affairs</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>VA-0038-2023</td>\n",
       "      <td>VA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Screening for esophageal adenocarcinoma</td>\n",
       "      <td>National VHA administrative data is used to ad...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Department of Veterans Affairs</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>VA-0039-2023</td>\n",
       "      <td>VA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Social determinants of health extractor</td>\n",
       "      <td>AI is used with clinical notes to identify soc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Department of Veterans Affairs</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>710 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Use_Case_ID Department_Code Agency Office  \\\n",
       "0    DOI-0000-2023             DOI    BLM    NaN   \n",
       "1    DOI-0001-2023             DOI    BOR    NaN   \n",
       "2    DOI-0002-2023             DOI    BOR    NaN   \n",
       "3    DOI-0003-2023             DOI    BOR    NaN   \n",
       "4    DOI-0004-2023             DOI    BOR    NaN   \n",
       "..             ...             ...    ...    ...   \n",
       "705   VA-0035-2023              VA    NaN    NaN   \n",
       "706   VA-0036-2023              VA    NaN    NaN   \n",
       "707   VA-0037-2023              VA    NaN    NaN   \n",
       "708   VA-0038-2023              VA    NaN    NaN   \n",
       "709   VA-0039-2023              VA    NaN    NaN   \n",
       "\n",
       "                                                 Title  \\\n",
       "0    Land Use Plan Document and Data Mining and Ana...   \n",
       "1    Seasonal/Temporary Wetland/Floodplain Delineat...   \n",
       "2    Data Driven Sub-Seasonal Forecasting of Temper...   \n",
       "3                   Data Driven Streamflow Forecasting   \n",
       "4                                    Snowcast Showdown   \n",
       "..                                                 ...   \n",
       "705  Extraction of family medical history from pati...   \n",
       "706  VA /IRB approved research study for finding co...   \n",
       "707                Interpretation/triage of eye images   \n",
       "708            Screening for esophageal adenocarcinoma   \n",
       "709            Social determinants of health extractor   \n",
       "\n",
       "                                               Summary  \\\n",
       "0    Exploring the potential to identify patterns, ...   \n",
       "1    Reclamation was interested in determining if r...   \n",
       "2    Reclamation has run 2, year-long prize competi...   \n",
       "3    Reclamation, along with partners from the CEAT...   \n",
       "4    Reclamation partnered with Bonneville Power Ad...   \n",
       "..                                                 ...   \n",
       "705  This pilot project uses TIU documentation on A...   \n",
       "706  This IRB approved research study uses  a rando...   \n",
       "707  Artificial intelligence supports triage of eye...   \n",
       "708  National VHA administrative data is used to ad...   \n",
       "709  AI is used with clinical notes to identify soc...   \n",
       "\n",
       "                   Development_Stage  \\\n",
       "0        Planned (not in production)   \n",
       "1                          Completed   \n",
       "2    Development (not in production)   \n",
       "3    Development (not in production)   \n",
       "4        Development and Acquisition   \n",
       "..                               ...   \n",
       "705                              NaN   \n",
       "706                              NaN   \n",
       "707                              NaN   \n",
       "708                              NaN   \n",
       "709                              NaN   \n",
       "\n",
       "                                            Techniques Source_Code  \\\n",
       "0    Natural Language Processing and Geo Classifica...         NaN   \n",
       "1    Image classification using Joint Unsupervised ...         NaN   \n",
       "2    Range of data driven, AI/ML techniques (e.g. r...         NaN   \n",
       "3    Range of data driven, AI/ML techniques (e.g. L...         NaN   \n",
       "4               Range of data driven, AI/ML techniques         NaN   \n",
       "..                                                 ...         ...   \n",
       "705                                                NaN         NaN   \n",
       "706                                                NaN         NaN   \n",
       "707                                                NaN         NaN   \n",
       "708                                                NaN         NaN   \n",
       "709                                                NaN         NaN   \n",
       "\n",
       "                         Department  ... split_dev_x split_dev_y start_t_x  \\\n",
       "0            Department of Interior  ...          19          33        17   \n",
       "1            Department of Interior  ...          17          16         3   \n",
       "2            Department of Interior  ...           5          27        20   \n",
       "3            Department of Interior  ...           6          27        24   \n",
       "4            Department of Interior  ...           7          27        21   \n",
       "..                              ...  ...         ...         ...       ...   \n",
       "705  Department of Veterans Affairs  ...          20          12        13   \n",
       "706  Department of Veterans Affairs  ...          21          12        14   \n",
       "707  Department of Veterans Affairs  ...          22          12        15   \n",
       "708  Department of Veterans Affairs  ...          23          12        16   \n",
       "709  Department of Veterans Affairs  ...          24          12        17   \n",
       "\n",
       "    start_t_y  split_t_x  split_t_y  start_dep_x  start_dep_y  split_dep_x  \\\n",
       "0          25         17         37            1            1            1   \n",
       "1          24          3         33            2            1            2   \n",
       "2          17         20         20            3            1            3   \n",
       "3          20         24         26            4            1            4   \n",
       "4          17         21         20            5            1            5   \n",
       "..        ...        ...        ...          ...          ...          ...   \n",
       "705        15         13         15            4           27            4   \n",
       "706        15         14         15            5           27            5   \n",
       "707        15         15         15            6           27            6   \n",
       "708        15         16         15            7           27            7   \n",
       "709        15         17         15            8           27            8   \n",
       "\n",
       "     split_dep_y  \n",
       "0              1  \n",
       "1              1  \n",
       "2              1  \n",
       "3              1  \n",
       "4              1  \n",
       "..           ...  \n",
       "705           42  \n",
       "706           42  \n",
       "707           42  \n",
       "708           42  \n",
       "709           42  \n",
       "\n",
       "[710 rows x 27 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"2023_ai_inventory_edit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "other = data.groupby('Department').size().reset_index(name='counts').sort_values('counts', ascending=False).iloc[5:][\"Department\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Department of Agriculture',\n",
       " 'Department of Interior',\n",
       " 'National Aeronautics and Space Administration',\n",
       " 'Department of State',\n",
       " 'Department of Labor',\n",
       " 'Department of Transportation',\n",
       " 'Department of Treasury',\n",
       " 'Social Security Administration',\n",
       " 'U.S. Agency for International Development',\n",
       " 'U.S. General Services Administration',\n",
       " 'National Archives and Records Administration',\n",
       " 'Department of Justice',\n",
       " 'U.S. Office of Personnel Management',\n",
       " 'U.S. Environmental Protection Agency',\n",
       " 'Department of Housing and Urban Development',\n",
       " 'Department of Education']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<option value=\"Department of Agriculture\">\n",
      "            Department of Agriculture (39)\n",
      "          </option>\n",
      "<option value=\"Department of Interior\">\n",
      "            Department of Interior (38)\n",
      "          </option>\n",
      "<option value=\"National Aeronautics and Space Administration\">\n",
      "            National Aeronautics and Space Administration (33)\n",
      "          </option>\n",
      "<option value=\"Department of State\">\n",
      "            Department of State (31)\n",
      "          </option>\n",
      "<option value=\"Department of Labor\">\n",
      "            Department of Labor (18)\n",
      "          </option>\n",
      "<option value=\"Department of Transportation\">\n",
      "            Department of Transportation (14)\n",
      "          </option>\n",
      "<option value=\"Department of Treasury\">\n",
      "            Department of Treasury (14)\n",
      "          </option>\n",
      "<option value=\"Social Security Administration\">\n",
      "            Social Security Administration (14)\n",
      "          </option>\n",
      "<option value=\"U.S. Agency for International Development\">\n",
      "            U.S. Agency for International Development (14)\n",
      "          </option>\n",
      "<option value=\"U.S. General Services Administration\">\n",
      "            U.S. General Services Administration (12)\n",
      "          </option>\n",
      "<option value=\"National Archives and Records Administration\">\n",
      "            National Archives and Records Administration (5)\n",
      "          </option>\n",
      "<option value=\"Department of Justice\">\n",
      "            Department of Justice (4)\n",
      "          </option>\n",
      "<option value=\"U.S. Office of Personnel Management\">\n",
      "            U.S. Office of Personnel Management (4)\n",
      "          </option>\n",
      "<option value=\"U.S. Environmental Protection Agency\">\n",
      "            U.S. Environmental Protection Agency (3)\n",
      "          </option>\n",
      "<option value=\"Department of Housing and Urban Development\">\n",
      "            Department of Housing and Urban Development (1)\n",
      "          </option>\n",
      "<option value=\"Department of Education\">\n",
      "            Department of Education (1)\n",
      "          </option>\n"
     ]
    }
   ],
   "source": [
    "for d in other:\n",
    "    print(f\"\"\"<option value=\"{d}\">\n",
    "            {d} ({len(data[data['Department'] == d])})\n",
    "          </option>\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Use_Case_ID</th>\n",
       "      <th>Department_Code</th>\n",
       "      <th>Agency</th>\n",
       "      <th>Office</th>\n",
       "      <th>Title</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Development_Stage</th>\n",
       "      <th>Techniques</th>\n",
       "      <th>Source_Code</th>\n",
       "      <th>Department</th>\n",
       "      <th>...</th>\n",
       "      <th>split_dev_x</th>\n",
       "      <th>split_dev_y</th>\n",
       "      <th>start_t_x</th>\n",
       "      <th>start_t_y</th>\n",
       "      <th>split_t_x</th>\n",
       "      <th>split_t_y</th>\n",
       "      <th>start_dep_x</th>\n",
       "      <th>start_dep_y</th>\n",
       "      <th>split_dep_x</th>\n",
       "      <th>split_dep_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DOI-0005-2023</td>\n",
       "      <td>DOI</td>\n",
       "      <td>BOR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PyForecast</td>\n",
       "      <td>Pyforecast is a statistical/ML water supply fo...</td>\n",
       "      <td>Implementation</td>\n",
       "      <td>Regression and related methods</td>\n",
       "      <td>https://github.com/usbr/PyForecast</td>\n",
       "      <td>Department of Interior</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>DOI-0031-2023</td>\n",
       "      <td>DOI</td>\n",
       "      <td>USGS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two-Dimensional Detailed Hydraulic Analysis</td>\n",
       "      <td>The USGS proposes to conduct analysis of detai...</td>\n",
       "      <td>Initiation</td>\n",
       "      <td>Doodler: https://github.com/dbuscombe-usgs/das...</td>\n",
       "      <td>https://github.com/dbuscombe-usgs/dash_doodler</td>\n",
       "      <td>Department of Interior</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>34</td>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>DOI-0037-2023</td>\n",
       "      <td>DOI</td>\n",
       "      <td>USGS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TMDL and Data Mining Investigations</td>\n",
       "      <td>Apply data-mining techniques, include artifici...</td>\n",
       "      <td>Operation and Maintenance</td>\n",
       "      <td>Deep convolutional neural networks; ResNet, Mo...</td>\n",
       "      <td>https://github.com/dbuscombe-usgs/MLMONDAYS</td>\n",
       "      <td>Department of Interior</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>17</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>GSA-0001-2023</td>\n",
       "      <td>GSA</td>\n",
       "      <td>FAS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>City Pairs Program Ticket Forecast and Scenari...</td>\n",
       "      <td>Takes segment-level City Pair Program air trav...</td>\n",
       "      <td>Development and Acquisition</td>\n",
       "      <td>Time Series Forecast</td>\n",
       "      <td>https://github.helix.gsa.gov/EDA/City_Pair_Pro...</td>\n",
       "      <td>U.S. General Services Administration</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>27</td>\n",
       "      <td>15</td>\n",
       "      <td>24</td>\n",
       "      <td>15</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>GSA-0009-2023</td>\n",
       "      <td>GSA</td>\n",
       "      <td>OGP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Solicitation Review Tool (SRT)</td>\n",
       "      <td>The SRT intakes SAM.gov data for all Informati...</td>\n",
       "      <td>Operation and Maintenance</td>\n",
       "      <td>Natural Language Processing (NLP); Intelligent...</td>\n",
       "      <td>https://github.com/GSA/srt-api</td>\n",
       "      <td>U.S. General Services Administration</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>38</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>NASA-0001-2023</td>\n",
       "      <td>NASA</td>\n",
       "      <td>Ames Research Center</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Biological and Physical Sciences (BPS) RNA Seq...</td>\n",
       "      <td>RNA sequencing data from spaceflown and contro...</td>\n",
       "      <td>In-use</td>\n",
       "      <td>GANs, Hierarchical Clustering</td>\n",
       "      <td>https://github.com/NASA-IMPACT/bps-numerical</td>\n",
       "      <td>National Aeronautics and Space Administration</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>27</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>NASA-0002-2023</td>\n",
       "      <td>NASA</td>\n",
       "      <td>Ames Research Center</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Biological and Physical Sciences Microscopy Be...</td>\n",
       "      <td>This study uses fluorescence microscopy images...</td>\n",
       "      <td>In-use</td>\n",
       "      <td>Graphical Neural Network</td>\n",
       "      <td>https://github.com/NASA-IMPACT/bps-imagery-rad...</td>\n",
       "      <td>National Aeronautics and Space Administration</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>27</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>NASA-0005-2023</td>\n",
       "      <td>NASA</td>\n",
       "      <td>Ames Research Center</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pre-trained microscopy image neural network En...</td>\n",
       "      <td>Convolutional Neural Network encoders were tra...</td>\n",
       "      <td>In-use</td>\n",
       "      <td>Transfer learning</td>\n",
       "      <td>https://github.com/nasa/pretrained-microscopy-...</td>\n",
       "      <td>National Aeronautics and Space Administration</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>NASA-0006-2023</td>\n",
       "      <td>NASA</td>\n",
       "      <td>Glenn Research Center</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Application that provides bio-inspired solutio...</td>\n",
       "      <td>PeTaL (the Periodic Table of Life) is an open ...</td>\n",
       "      <td>In-use</td>\n",
       "      <td>LLM prompt engineering, BERT text classificati...</td>\n",
       "      <td>https://github.com/nasa-petal</td>\n",
       "      <td>National Aeronautics and Space Administration</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>26</td>\n",
       "      <td>15</td>\n",
       "      <td>38</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>NASA-0008-2023</td>\n",
       "      <td>NASA</td>\n",
       "      <td>Goddard Space Flight Center</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Europa Ice Floe Detection (GSFC Planetary Scie...</td>\n",
       "      <td>Machine Learning applied to Galileo space prob...</td>\n",
       "      <td>In-use</td>\n",
       "      <td>Mask R-CNN, GANs</td>\n",
       "      <td>https://gitlab.grc.nasa.gov/kgansler/europa-ic...</td>\n",
       "      <td>National Aeronautics and Space Administration</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "      <td>26</td>\n",
       "      <td>21</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>NASA-0009-2023</td>\n",
       "      <td>NASA</td>\n",
       "      <td>Goddard Space Flight Center</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Titan Methane Cloud Detection (GSFC Planetary ...</td>\n",
       "      <td>Machine Learning applied to Cassini space prob...</td>\n",
       "      <td>In-use</td>\n",
       "      <td>Mask R-CNN, U-net image Recognition</td>\n",
       "      <td>https://gitlab.grc.nasa.gov/zyahn/titan-clouds...</td>\n",
       "      <td>National Aeronautics and Space Administration</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>NASA-0019-2023</td>\n",
       "      <td>NASA</td>\n",
       "      <td>Langley Research Center</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Geophysical Observations Toolkit for Evaluatin...</td>\n",
       "      <td>Three capstone projects conducted 2021-2022 wi...</td>\n",
       "      <td>In-use</td>\n",
       "      <td>support vector machine, artificial neural network</td>\n",
       "      <td>https://ntrs.nasa.gov/citations/20220010955</td>\n",
       "      <td>National Aeronautics and Space Administration</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>NASA-0021-2023</td>\n",
       "      <td>NASA</td>\n",
       "      <td>Langley Research Center</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pedestrian Safety Corridors for Drone Test Range</td>\n",
       "      <td>NASA Langley Research Center (LaRC) is activel...</td>\n",
       "      <td>In-use</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://gitlab.grc.nasa.gov/dmtrent/wahldo-1</td>\n",
       "      <td>National Aeronautics and Space Administration</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>USDA-0016-2023</td>\n",
       "      <td>USDA</td>\n",
       "      <td>USDA</td>\n",
       "      <td>FPAC</td>\n",
       "      <td>Land Change Analysis Tool (LCAT)</td>\n",
       "      <td>We employ a random forest machine learning cla...</td>\n",
       "      <td>Operation and Management</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>https://cran.r-project.org/web/packages/random...</td>\n",
       "      <td>Department of Agriculture</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>USDA-0017-2023</td>\n",
       "      <td>USDA</td>\n",
       "      <td>USDA</td>\n",
       "      <td>Federal CDO Council</td>\n",
       "      <td>OCIO/CDO Council Comment Analysis Tool</td>\n",
       "      <td>The Comment Analysis pilot has shown that a to...</td>\n",
       "      <td>Development and Acquisition</td>\n",
       "      <td>Natural Language Processing</td>\n",
       "      <td>https://gcc02.safelinks.protection.outlook.com...</td>\n",
       "      <td>Department of Agriculture</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>38</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>USDA-0019-2023</td>\n",
       "      <td>USDA</td>\n",
       "      <td>USDA</td>\n",
       "      <td>Forest Service</td>\n",
       "      <td>Wildland Urban Interface - Mapping Wildfire Loss</td>\n",
       "      <td>This is a proof-of-concept study to investigat...</td>\n",
       "      <td>Development and Acquisition</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "      <td>Department of Agriculture</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>24</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>USDA-0021-2023</td>\n",
       "      <td>USDA</td>\n",
       "      <td>USDA</td>\n",
       "      <td>Forest Service</td>\n",
       "      <td>RMRS Raster Utility</td>\n",
       "      <td>RMRS Raster Utility is a .NET object oriented ...</td>\n",
       "      <td>Operation and Management</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>https://collab.firelab.org/software/projects/r...</td>\n",
       "      <td>Department of Agriculture</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>26</td>\n",
       "      <td>18</td>\n",
       "      <td>26</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Use_Case_ID Department_Code                       Agency  \\\n",
       "5     DOI-0005-2023             DOI                          BOR   \n",
       "31    DOI-0031-2023             DOI                         USGS   \n",
       "37    DOI-0037-2023             DOI                         USGS   \n",
       "110   GSA-0001-2023             GSA                          FAS   \n",
       "118   GSA-0009-2023             GSA                          OGP   \n",
       "128  NASA-0001-2023            NASA         Ames Research Center   \n",
       "129  NASA-0002-2023            NASA         Ames Research Center   \n",
       "132  NASA-0005-2023            NASA         Ames Research Center   \n",
       "133  NASA-0006-2023            NASA        Glenn Research Center   \n",
       "135  NASA-0008-2023            NASA  Goddard Space Flight Center   \n",
       "136  NASA-0009-2023            NASA  Goddard Space Flight Center   \n",
       "146  NASA-0019-2023            NASA      Langley Research Center   \n",
       "148  NASA-0021-2023            NASA      Langley Research Center   \n",
       "222  USDA-0016-2023            USDA                         USDA   \n",
       "223  USDA-0017-2023            USDA                         USDA   \n",
       "225  USDA-0019-2023            USDA                         USDA   \n",
       "227  USDA-0021-2023            USDA                         USDA   \n",
       "\n",
       "                  Office                                              Title  \\\n",
       "5                    NaN                                         PyForecast   \n",
       "31                   NaN        Two-Dimensional Detailed Hydraulic Analysis   \n",
       "37                   NaN                TMDL and Data Mining Investigations   \n",
       "110                  NaN  City Pairs Program Ticket Forecast and Scenari...   \n",
       "118                  NaN                     Solicitation Review Tool (SRT)   \n",
       "128                  NaN  Biological and Physical Sciences (BPS) RNA Seq...   \n",
       "129                  NaN  Biological and Physical Sciences Microscopy Be...   \n",
       "132                  NaN  Pre-trained microscopy image neural network En...   \n",
       "133                  NaN  Application that provides bio-inspired solutio...   \n",
       "135                  NaN  Europa Ice Floe Detection (GSFC Planetary Scie...   \n",
       "136                  NaN  Titan Methane Cloud Detection (GSFC Planetary ...   \n",
       "146                  NaN  Geophysical Observations Toolkit for Evaluatin...   \n",
       "148                  NaN   Pedestrian Safety Corridors for Drone Test Range   \n",
       "222                 FPAC                   Land Change Analysis Tool (LCAT)   \n",
       "223  Federal CDO Council             OCIO/CDO Council Comment Analysis Tool   \n",
       "225       Forest Service   Wildland Urban Interface - Mapping Wildfire Loss   \n",
       "227       Forest Service                                RMRS Raster Utility   \n",
       "\n",
       "                                               Summary  \\\n",
       "5    Pyforecast is a statistical/ML water supply fo...   \n",
       "31   The USGS proposes to conduct analysis of detai...   \n",
       "37   Apply data-mining techniques, include artifici...   \n",
       "110  Takes segment-level City Pair Program air trav...   \n",
       "118  The SRT intakes SAM.gov data for all Informati...   \n",
       "128  RNA sequencing data from spaceflown and contro...   \n",
       "129  This study uses fluorescence microscopy images...   \n",
       "132  Convolutional Neural Network encoders were tra...   \n",
       "133  PeTaL (the Periodic Table of Life) is an open ...   \n",
       "135  Machine Learning applied to Galileo space prob...   \n",
       "136  Machine Learning applied to Cassini space prob...   \n",
       "146  Three capstone projects conducted 2021-2022 wi...   \n",
       "148  NASA Langley Research Center (LaRC) is activel...   \n",
       "222  We employ a random forest machine learning cla...   \n",
       "223  The Comment Analysis pilot has shown that a to...   \n",
       "225  This is a proof-of-concept study to investigat...   \n",
       "227  RMRS Raster Utility is a .NET object oriented ...   \n",
       "\n",
       "               Development_Stage  \\\n",
       "5                 Implementation   \n",
       "31                    Initiation   \n",
       "37     Operation and Maintenance   \n",
       "110  Development and Acquisition   \n",
       "118    Operation and Maintenance   \n",
       "128                       In-use   \n",
       "129                       In-use   \n",
       "132                       In-use   \n",
       "133                       In-use   \n",
       "135                       In-use   \n",
       "136                       In-use   \n",
       "146                       In-use   \n",
       "148                       In-use   \n",
       "222     Operation and Management   \n",
       "223  Development and Acquisition   \n",
       "225  Development and Acquisition   \n",
       "227     Operation and Management   \n",
       "\n",
       "                                            Techniques  \\\n",
       "5                       Regression and related methods   \n",
       "31   Doodler: https://github.com/dbuscombe-usgs/das...   \n",
       "37   Deep convolutional neural networks; ResNet, Mo...   \n",
       "110                               Time Series Forecast   \n",
       "118  Natural Language Processing (NLP); Intelligent...   \n",
       "128                      GANs, Hierarchical Clustering   \n",
       "129                           Graphical Neural Network   \n",
       "132                                  Transfer learning   \n",
       "133  LLM prompt engineering, BERT text classificati...   \n",
       "135                                   Mask R-CNN, GANs   \n",
       "136                Mask R-CNN, U-net image Recognition   \n",
       "146  support vector machine, artificial neural network   \n",
       "148                                                NaN   \n",
       "222                                   Machine Learning   \n",
       "223                        Natural Language Processing   \n",
       "225                                   Machine Learning   \n",
       "227                                   Machine Learning   \n",
       "\n",
       "                                           Source_Code  \\\n",
       "5                   https://github.com/usbr/PyForecast   \n",
       "31      https://github.com/dbuscombe-usgs/dash_doodler   \n",
       "37         https://github.com/dbuscombe-usgs/MLMONDAYS   \n",
       "110  https://github.helix.gsa.gov/EDA/City_Pair_Pro...   \n",
       "118                     https://github.com/GSA/srt-api   \n",
       "128       https://github.com/NASA-IMPACT/bps-numerical   \n",
       "129  https://github.com/NASA-IMPACT/bps-imagery-rad...   \n",
       "132  https://github.com/nasa/pretrained-microscopy-...   \n",
       "133                      https://github.com/nasa-petal   \n",
       "135  https://gitlab.grc.nasa.gov/kgansler/europa-ic...   \n",
       "136  https://gitlab.grc.nasa.gov/zyahn/titan-clouds...   \n",
       "146        https://ntrs.nasa.gov/citations/20220010955   \n",
       "148       https://gitlab.grc.nasa.gov/dmtrent/wahldo-1   \n",
       "222  https://cran.r-project.org/web/packages/random...   \n",
       "223  https://gcc02.safelinks.protection.outlook.com...   \n",
       "225  https://www.sciencedirect.com/science/article/...   \n",
       "227  https://collab.firelab.org/software/projects/r...   \n",
       "\n",
       "                                        Department  ... split_dev_x  \\\n",
       "5                           Department of Interior  ...          18   \n",
       "31                          Department of Interior  ...           6   \n",
       "37                          Department of Interior  ...          24   \n",
       "110           U.S. General Services Administration  ...          24   \n",
       "118           U.S. General Services Administration  ...          23   \n",
       "128  National Aeronautics and Space Administration  ...          27   \n",
       "129  National Aeronautics and Space Administration  ...           1   \n",
       "132  National Aeronautics and Space Administration  ...           4   \n",
       "133  National Aeronautics and Space Administration  ...           5   \n",
       "135  National Aeronautics and Space Administration  ...           7   \n",
       "136  National Aeronautics and Space Administration  ...           8   \n",
       "146  National Aeronautics and Space Administration  ...          18   \n",
       "148  National Aeronautics and Space Administration  ...          20   \n",
       "222                      Department of Agriculture  ...           6   \n",
       "223                      Department of Agriculture  ...          27   \n",
       "225                      Department of Agriculture  ...           1   \n",
       "227                      Department of Agriculture  ...           9   \n",
       "\n",
       "    split_dev_y start_t_x start_t_y  split_t_x  split_t_y  start_dep_x  \\\n",
       "5            16         4        24          4         33            6   \n",
       "31           34        22        17         22         20            5   \n",
       "37           16        17        21         17         27           11   \n",
       "110          27        15        24         15         33            3   \n",
       "118          17        11        26         11         38           11   \n",
       "128          20        23        21         23         27           21   \n",
       "129          21        24        21         24         27           22   \n",
       "132          21         7        18          7         21           25   \n",
       "133          21        15        26         15         38           26   \n",
       "135          21        26        21         26         27            1   \n",
       "136          21        27        21         27         27            2   \n",
       "146          21         2        22          2         28           12   \n",
       "148          21         7        12          7         12           14   \n",
       "222          23        22        18         22         21            7   \n",
       "223          29        26        26         26         38            8   \n",
       "225          30        24        18         24         21           10   \n",
       "227          23        26        18         26         21           12   \n",
       "\n",
       "     start_dep_y  split_dep_x  split_dep_y  \n",
       "5              1            6            1  \n",
       "31             2            5            2  \n",
       "37             2           11            2  \n",
       "110            5            3            5  \n",
       "118            5           11            5  \n",
       "128            5           21            5  \n",
       "129            5           22            5  \n",
       "132            5           25            5  \n",
       "133            5           26            5  \n",
       "135            6            1            6  \n",
       "136            6            2            6  \n",
       "146            6           12            6  \n",
       "148            6           14            6  \n",
       "222            9            7            9  \n",
       "223            9            8            9  \n",
       "225            9           10            9  \n",
       "227            9           12            9  \n",
       "\n",
       "[17 rows x 27 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['Source_Code'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_clean(export:bool = True):\n",
    "    data = pd.read_csv(\"2023_ai_inventory.csv\")\n",
    "    df_clean = process_data(data)\n",
    "\n",
    "    for col in ['dev_edit', 'tech_edit', 'dep_edit']:\n",
    "        df_clean = starting_grid(df_clean, col)\n",
    "        df_clean = split_grid(df_clean, col)\n",
    "\n",
    "    if export:\n",
    "        df_clean.to_csv('2023_ai_inventory_edit.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(df):\n",
    "\n",
    "    # clean up dev stage\n",
    "    # In Use\n",
    "    stages = {'In Use': ['Operation and Maintenance','In-use', 'Implementation', \n",
    "                     'Operation and Management','In mission', 'In production: more than 1 year', \n",
    "                     'In production: less than six months', 'Completed','In production: less than one year', 'Deployment', \n",
    "                     'Technical transfer of capability to industry planned this summer', 'In production: less than 6 months' ,\n",
    "                      'Technical transfer of capability to industry planned this summer.' , 'OPC runs in a pseudo-operational capacity via a webpage maintained by the Massachusetts Institute of Technology - Lincoln Lab, as well as in a test and evaluation capacity in a research mode.'],\n",
    "          'In Planning': ['Initiation', 'Planned (not in production)', 'Investigating/Proof of concept' ],\n",
    "          'In Development': ['Development and Acquisition', 'Development (not in production)', 'Proof-of-concept completed',\n",
    "                             'Currently under development', \"This is a pilot initiative\", \"User Acceptance Testing to begin early spring '22\",\n",
    "                               'Proof of Concept completed and published', 'Initial development', 'Refinments planned for future release', 'Successfully tested but not in production.'],\n",
    "          'No Development Stage Indicated': [np.nan]\n",
    "                }\n",
    "\n",
    "    # Initialize the new column with None or any default value\n",
    "    df['dev_edit'] = None\n",
    "\n",
    "    # Iterate through the dictionary and update the new column\n",
    "    for key, stage_list in stages.items():\n",
    "        df.loc[df['Development_Stage'].isin(stage_list), 'dev_edit'] = key\n",
    "\n",
    "    #clean up technique\n",
    "    nlp = ['nlp', 'natural language']\n",
    "    nn = ['neural network', 'nn', 'lstm', 'gans', 'synthetic']\n",
    "    gml = ['machine learning', 'ml', 'ai', 'artificial intelligence', \n",
    "        'reinforcement','doodler', 'transfer']\n",
    "    llm = ['large language']\n",
    "    mv = ['machine vision', 'computer vision']\n",
    "    reg = ['regression']\n",
    "    classifiers = ['classifier', 'forest', 'classification', 'identification']\n",
    "    ts = ['time series', 'forecasting']\n",
    "    other = ['other', 'unknown', 'big data', 'automation', 'sql', 'visual', 'fuzzy']\n",
    "\n",
    "    def sort_by_techniques(technique):\n",
    "        if pd.isnull(technique):\n",
    "            return 'No Technique Provided'\n",
    "        for cat, list in options:\n",
    "            if any(match in technique.lower() for match in list):\n",
    "                return cat\n",
    "        \n",
    "        return 'review'\n",
    "\n",
    "    options = [('Natural Language Processing', nlp),('Neural Network', nn) \n",
    "            , (\"Unspecified Machine Learning\", gml), ('Machine Vision',mv),\n",
    "            ('Regression', reg), ('Classification', classifiers),(\"Large Language Model\", llm),\n",
    "                ('Time Series Forecast', ts), ('Other', other)]\n",
    "    \n",
    "    df['tech_clean'] = df['Techniques'].apply(lambda x: sort_by_techniques(x))\n",
    "\n",
    "    top5_tech  = df.groupby('tech_clean')['Use_Case_ID'].count().sort_values(ascending=False).head(6).reset_index()['tech_clean'].tolist()\n",
    "    df['tech_edit'] = df['tech_clean'].apply(lambda x: x if x in top5_tech else 'Other')\n",
    "\n",
    "\n",
    "    # clean up department\n",
    "    top5_dep  = df.groupby('Department')['Use_Case_ID'].count().sort_values(ascending=False).head(5).reset_index()['Department'].tolist()\n",
    "    df['dep_edit'] = df['Department'].apply(lambda x: x if x in top5_dep else 'All Other Departments')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_chart_xy(df, col, col_count):\n",
    "    \n",
    "    dict = {}\n",
    "    # for now\n",
    "    \n",
    "    values = df[col].unique().tolist()\n",
    "    values.sort()\n",
    "    # 5 wide means first is at 3 then +5\n",
    "    i = 0\n",
    "    for v in values:\n",
    "        dict[v] = i\n",
    "        i += 1\n",
    "\n",
    "    df['rn'] = df.sort_values([col,'Use_Case_ID'], ascending=[True,True]) \\\n",
    "             .groupby([col]) \\\n",
    "             .cumcount()\n",
    "    df['x'] = (df[col].map(dict) * 7) + (df['rn'] % col_count) +1\n",
    "    df['y'] = df['rn'] // col_count + 1\n",
    "\n",
    "    x_name = col + '_x'\n",
    "    y_name = col + '_y'\n",
    "    df = df.rename(columns={'x': x_name, 'y': y_name})\n",
    "    df.drop(columns=['rn'], inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def create_orderd_cats(df, col):\n",
    "    cats = df.groupby(col)['Use_Case_ID'].count().reset_index().sort_values('Use_Case_ID', ascending=False)[col].to_list()\n",
    "\n",
    "    # put others first\n",
    "    if 'Development' in cats:\n",
    "        cats.remove('No Development Stage Indicated')\n",
    "        cats.insert(0, 'No Development Stage Indicated')\n",
    "    elif \"No Technique Provided\" in cats:\n",
    "        cats.remove('No Technique Provided')\n",
    "        cats.insert(0, 'No Technique Provided')\n",
    "    \n",
    "    return cats\n",
    "    \n",
    "def starting_grid(df, start_col, max_x = 27):\n",
    "\n",
    "    if start_col == 'dev_edit':\n",
    "        c = 'dev'\n",
    "\n",
    "    elif start_col == 'tech_edit':\n",
    "        c = 't'\n",
    "    elif start_col == 'dep_edit':\n",
    "        c = 'dep'\n",
    "    \n",
    "    \n",
    "    col = f\"start_{c}\"\n",
    "    x_name = col + '_x'\n",
    "    y_name = col + '_y'\n",
    "\n",
    "    #TODO\n",
    "\n",
    "    ordered_cats = create_orderd_cats(df, start_col)\n",
    "\n",
    "    df[start_col] = pd.Categorical(df[start_col], ordered=True, \n",
    "                              categories=ordered_cats)\n",
    "        \n",
    "    df = df.sort_values([start_col, 'Use_Case_ID']).reset_index(drop=True) \n",
    "\n",
    "\n",
    "    df['rn'] = df.index\n",
    "\n",
    "    df[x_name] = df['rn'] % max_x + 1\n",
    "    df[y_name] = df['rn'] // max_x + 1\n",
    " \n",
    "    return df \n",
    "\n",
    "def split_grid(df, split_col, max_x = 27, max_y=27 ):\n",
    "\n",
    "    if split_col == 'dev_edit':\n",
    "        c = 'dev'\n",
    "    elif split_col == 'tech_edit':\n",
    "        c = 't'\n",
    "    elif split_col == 'dep_edit':\n",
    "        c = 'dep'\n",
    "    \n",
    "    \n",
    "    col = f\"split_{c}\"\n",
    "\n",
    "    #df = df.sort_values([split_col, 'Use_Case_ID']).reset_index(drop=True) \n",
    "\n",
    "    # df['rn'] = df.index \n",
    "    x_name = col + '_x'\n",
    "    y_name = col + '_y'\n",
    "\n",
    "    df[x_name] = df['rn'] % max_x + 1\n",
    "\n",
    "    dict = {}\n",
    "    i = 0\n",
    "    for val in df[split_col].unique():\n",
    "        dict[val] = i\n",
    "        i += 3\n",
    "        \n",
    "    df[y_name] = df.apply(lambda x: x['rn'] // max_y + 1 + dict[x[split_col]], axis=1)\n",
    "  \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 710 models\n",
    "* every model has a unique case id and department code (should use department)\n",
    "* \n",
    "* 10% are missing agency. adding new col for chart to just replace with department name\n",
    "    * Departments either have agency or dont (HUD, Labor, Treasury, VA, and EPA have no agency info)\n",
    "* Only Agriculture and Health and Human Services have office info\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Use_Case_ID           0.000000\n",
       "Department_Code       0.000000\n",
       "Agency               10.704225\n",
       "Office               72.394366\n",
       "Title                 0.000000\n",
       "Summary               0.000000\n",
       "Development_Stage    45.211268\n",
       "Techniques           55.633803\n",
       "Source_Code          97.605634\n",
       "Department            0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data.isnull().sum() / len(data)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Fluid migration from well-to-well communication will be inputted in AI to determine a costs-benefit analysis</td>\n",
       "      <td>This project will develop an ML algorithm to predict the time when a \\ngrowing fracture will reach the monitored well. The ML workflow will be \\ntrained on the distinctive tensile strain signature that precedes the \\ngrowing fracture. The new workflow will be designed to work in \\nconjunction with the fracture warning ML workflow developed in EY21. \\nTogether, these workflows will: (1) provide an early warning of well-to-\\nwell communication, (2) predict the measured depths where the \\ncommunication will happen, and (3) provide an estimated time until the \\nbeginning of well-to-well communication.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>To drive insights on the dependencies between the natural gas and electricity sectors to increase reliability of the NG system</td>\n",
       "      <td>Commercially available models will be used to generate predictive \\nscenarios</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>To drive insights on the power system reliability, cost, and operations during the energy transition with and without FECM technologies</td>\n",
       "      <td>Commercially available models will be used to generate predictive \\nscenarios</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>Using recursive neural networks and using fiber optic cables to recognize strain patterns and warn operators a fracture is coming.</td>\n",
       "      <td>This project will develop an ML algorithm to predict the time when a \\ngrowing fracture will reach the monitored well. The ML workflow will be \\ntrained on the distinctive tensile strain signature that precedes the \\ngrowing fracture. The new workflow will be designed to work in \\nconjunction with the fracture warning ML workflow developed in EY21. \\nTogether, these workflows will: (1) provide an early warning of well-to-\\nwell communication, (2) predict the measured depths where the \\ncommunication will happen, and (3) provide an estimated time until the \\nbeginning of well-to-well communication.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>Form Recognizer for Benefits Forms</td>\n",
       "      <td>Custom machine learning model to extract data from complex forms to tag data entries to field headers. The input is a document or scanned image of the form and the output is a JSON response with key/value pairs extracted by running the form against the custom trained model.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>Data Ingestion of Payroll Forms</td>\n",
       "      <td>Custom machine learning model to extract data from complex forms to tag data entries to field headers. The input is a document or scanned image of the form and the output is a JSON response with key/value pairs extracted by running the form against the custom trained model.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>R+2:18eDIRECT: Clarivate</td>\n",
       "      <td>AI to identify drug repurposing candidates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>ReDIRECT: AriScience</td>\n",
       "      <td>AI to identify drug repurposing candidates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>Machine learning models to predict disease progression among veterans with hepatitis C virus</td>\n",
       "      <td>A machine learning model is used to predict disease progression among veterans with hepatitis C virus.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>Reinforcement learning evaluation of treatment policies for patients with hepatitis C virus</td>\n",
       "      <td>A machine learning model is used to predict disease progression among veterans with hepatitis C virus.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                       Title  \\\n",
       "140                             Fluid migration from well-to-well communication will be inputted in AI to determine a costs-benefit analysis   \n",
       "159           To drive insights on the dependencies between the natural gas and electricity sectors to increase reliability of the NG system   \n",
       "160  To drive insights on the power system reliability, cost, and operations during the energy transition with and without FECM technologies   \n",
       "243       Using recursive neural networks and using fiber optic cables to recognize strain patterns and warn operators a fracture is coming.   \n",
       "310                                                                                                       Form Recognizer for Benefits Forms   \n",
       "316                                                                                                          Data Ingestion of Payroll Forms   \n",
       "392                                                                                                                 R+2:18eDIRECT: Clarivate   \n",
       "393                                                                                                                     ReDIRECT: AriScience   \n",
       "696                                             Machine learning models to predict disease progression among veterans with hepatitis C virus   \n",
       "701                                              Reinforcement learning evaluation of treatment policies for patients with hepatitis C virus   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Summary  \n",
       "140  This project will develop an ML algorithm to predict the time when a \\ngrowing fracture will reach the monitored well. The ML workflow will be \\ntrained on the distinctive tensile strain signature that precedes the \\ngrowing fracture. The new workflow will be designed to work in \\nconjunction with the fracture warning ML workflow developed in EY21. \\nTogether, these workflows will: (1) provide an early warning of well-to-\\nwell communication, (2) predict the measured depths where the \\ncommunication will happen, and (3) provide an estimated time until the \\nbeginning of well-to-well communication.  \n",
       "159                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Commercially available models will be used to generate predictive \\nscenarios  \n",
       "160                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Commercially available models will be used to generate predictive \\nscenarios  \n",
       "243  This project will develop an ML algorithm to predict the time when a \\ngrowing fracture will reach the monitored well. The ML workflow will be \\ntrained on the distinctive tensile strain signature that precedes the \\ngrowing fracture. The new workflow will be designed to work in \\nconjunction with the fracture warning ML workflow developed in EY21. \\nTogether, these workflows will: (1) provide an early warning of well-to-\\nwell communication, (2) predict the measured depths where the \\ncommunication will happen, and (3) provide an estimated time until the \\nbeginning of well-to-well communication.  \n",
       "310                                                                                                                                                                                                                                                                                                                                            Custom machine learning model to extract data from complex forms to tag data entries to field headers. The input is a document or scanned image of the form and the output is a JSON response with key/value pairs extracted by running the form against the custom trained model.  \n",
       "316                                                                                                                                                                                                                                                                                                                                            Custom machine learning model to extract data from complex forms to tag data entries to field headers. The input is a document or scanned image of the form and the output is a JSON response with key/value pairs extracted by running the form against the custom trained model.  \n",
       "392                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    AI to identify drug repurposing candidates  \n",
       "393                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    AI to identify drug repurposing candidates  \n",
       "696                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        A machine learning model is used to predict disease progression among veterans with hepatitis C virus.  \n",
       "701                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        A machine learning model is used to predict disease progression among veterans with hepatitis C virus.  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "data[data.duplicated('Summary', keep=False)][[\"Title\", \"Summary\"]]\n",
    "\n",
    "# exact duplicates?\n",
    "#these look to be different use cases, so we'll keep them all\n",
    "#data[data['Use_Case_ID'].isin(['DOC-0024-2023', 'DOC-0025-2023'])]['Summary'].values\n",
    "\n",
    "#data[data['Use_Case_ID'].isin(['DOT-0007-2023', 'DOT-0008-2023'])]['Summary'].values\n",
    "\n",
    "#data[data['Use_Case_ID'].isin(['HHS-0006-2023', 'HHS-0007-2023'])]['Summary'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Department\n",
       "Department of Agriculture                          0.0\n",
       "Department of Commerce                             0.0\n",
       "Department of Education                            0.0\n",
       "Department of Energy                               0.0\n",
       "Department of Health and Human Services            0.0\n",
       "Department of Homeland Security                    0.0\n",
       "Department of Housing and Urban Development      100.0\n",
       "Department of Interior                             0.0\n",
       "Department of Justice                              0.0\n",
       "Department of Labor                              100.0\n",
       "Department of State                                0.0\n",
       "Department of Transportation                       0.0\n",
       "Department of Treasury                           100.0\n",
       "Department of Veterans Affairs                   100.0\n",
       "National Aeronautics and Space Administration      0.0\n",
       "National Archives and Records Administration       0.0\n",
       "Social Security Administration                     0.0\n",
       "U.S. Agency for International Development          0.0\n",
       "U.S. Environmental Protection Agency             100.0\n",
       "U.S. General Services Administration               0.0\n",
       "U.S. Office of Personnel Management                0.0\n",
       "Name: Agency, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#which department has the most missing agency data\n",
    "(data.groupby('Department')['Agency'].apply(lambda x: (x.isnull().sum() / len(x)) * 100))\n",
    "#(data.groupby('Department')['Office'].apply(lambda x: (x.isnull().sum() / len(x)) * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Office\n",
       "ACF Children's Bureau                                                                            1\n",
       "AHRQ                                                                                             2\n",
       "BARDA (CBRN & DRIVe)                                                                             2\n",
       "BARDA (CBRN)                                                                                     4\n",
       "BARDA (DRIVe)                                                                                    5\n",
       "CBER/OBPV/DABRA                                                                                  3\n",
       "CDER/Office of Generic Drugs                                                                     4\n",
       "CDER/Office of New Drugs                                                                         1\n",
       "CDER/Office of Pharmaceutical Quality (OPQ)                                                      1\n",
       "CDER/Office of Strategic Programs (OSP)                                                          1\n",
       "CDER/Office of Surveillance and Epidemiology (OSE)                                              11\n",
       "CDER/Office of Translational Sciences                                                            1\n",
       "CDER/Office of Translational Sciences/Office of Biostatistics                                    2\n",
       "CDER/Office of Translational Sciences/Office of Clinical Pharmacology                            1\n",
       "CFSAN /OFAS                                                                                      1\n",
       "CFSAN/OFAS                                                                                       2\n",
       "CSELS                                                                                            3\n",
       "CTP/OS/DRSI                                                                                      3\n",
       "CVM                                                                                              1\n",
       "Centers for Medicare & Medicaid Services (CMS)                                                  23\n",
       "Chief Data Officer                                                                               1\n",
       "NCCDPHP/DDT                                                                                      1\n",
       "NCCDPHP/DNPAO                                                                                    4\n",
       "NCEZID                                                                                           1\n",
       "NCHS                                                                                             8\n",
       "NCIPC/DIP                                                                                        1\n",
       "NCIRD                                                                                            1\n",
       "NCTR                                                                                            12\n",
       "National Institutes of Health (NIH) CC                                                           1\n",
       "National Institutes of Health (NIH) CSR                                                          1\n",
       "National Institutes of Health (NIH) NCI                                                          1\n",
       "National Institutes of Health (NIH) NHLBI                                                        1\n",
       "National Institutes of Health (NIH) NIAID                                                        5\n",
       "National Institutes of Health (NIH) NIDCR                                                        2\n",
       "National Institutes of Health (NIH) NIEHS                                                        3\n",
       "National Institutes of Health (NIH) NIGMS                                                        4\n",
       "National Institutes of Health (NIH) NLM                                                         14\n",
       "National Institutes of Health (NIH) OD/DPCPSI/OAR                                                1\n",
       "National Institutes of Health (NIH) OD/DPCPSI/OPA                                                6\n",
       "National Institutes of Health (NIH) OD/OER                                                       3\n",
       "National Institutes of Health (NIH) OD/ORF                                                       5\n",
       "OIG                                                                                              2\n",
       "Office of Critical Infrastructure                                                                1\n",
       "Office of Information Management, Data and Analytics                                             1\n",
       "Office of Information Management, Data and Analytics/Division of Supply Chain Control Tower      1\n",
       "Office of Information Management, Data, and Analytics/Division of Modeling and Simulation        1\n",
       "Office of Information Management, Data, and Analytics/Division of Supply Chain Control Tower     1\n",
       "Office of Information Management, Data, and Analytics/ODA                                        2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"Department\"] == 'Department of Health and Human Services'].groupby(\"Office\", dropna=False).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use_Case_ID\n",
      "DHS-0000-2023    1\n",
      "HHS-0055-2023    1\n",
      "HHS-0079-2023    1\n",
      "HHS-0080-2023    1\n",
      "HHS-0081-2023    1\n",
      "dtype: int64\n",
      "Department_Code\n",
      "DOE    178\n",
      "HHS    157\n",
      "DOC     49\n",
      "DHS     41\n",
      "VA      40\n",
      "dtype: int64\n",
      "Agency\n",
      "National Energy Technology Laboratory    127\n",
      "NaN                                       76\n",
      "NIH                                       47\n",
      "FDA                                       44\n",
      "USDA                                      39\n",
      "dtype: int64\n",
      "Office\n",
      "NaN                                                   514\n",
      "Centers for Medicare & Medicaid Services (CMS)         23\n",
      "National Institutes of Health (NIH) NLM                14\n",
      "NCTR                                                   12\n",
      "CDER/Office of Surveillance and Epidemiology (OSE)     11\n",
      "dtype: int64\n",
      "Title\n",
      "Machine Learning for Occupant Safety Research    2\n",
      "Burn & Blast MCMs: Philips                       2\n",
      "First Guess Excessive Rainfall Outlook           2\n",
      "PyForecast                                       1\n",
      "Privileged Material Identification               1\n",
      "dtype: int64\n",
      "Summary\n",
      "A machine learning model is used to predict disease progression among veterans with hepatitis C virus.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          2\n",
      "Commercially available models will be used to generate predictive \\nscenarios                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   2\n",
      "Custom machine learning model to extract data from complex forms to tag data entries to field headers. The input is a document or scanned image of the form and the output is a JSON response with key/value pairs extracted by running the form against the custom trained model.                                                                                                                                                                                                                                                                                                                                              2\n",
      "AI to identify drug repurposing candidates                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      2\n",
      "This project will develop an ML algorithm to predict the time when a \\ngrowing fracture will reach the monitored well. The ML workflow will be \\ntrained on the distinctive tensile strain signature that precedes the \\ngrowing fracture. The new workflow will be designed to work in \\nconjunction with the fracture warning ML workflow developed in EY21. \\nTogether, these workflows will: (1) provide an early warning of well-to-\\nwell communication, (2) predict the measured depths where the \\ncommunication will happen, and (3) provide an estimated time until the \\nbeginning of well-to-well communication.    2\n",
      "dtype: int64\n",
      "Development_Stage\n",
      "NaN                            321\n",
      "Operation and Maintenance       91\n",
      "Development and Acquisition     81\n",
      "Initiation                      74\n",
      "Implementation                  50\n",
      "dtype: int64\n",
      "Techniques\n",
      "NaN                                395\n",
      "Other                               31\n",
      "Machine Learning                    30\n",
      "Artificial Intelligence Unknown     26\n",
      "Big Data, Other                     14\n",
      "dtype: int64\n",
      "Source_Code\n",
      "NaN                                                                                                                               693\n",
      "https://cran.r-project.org/web/packages/randomForest/randomForest.pdf<br>https://cran.r-project.org/web/packages/clhs/clhs.pdf      1\n",
      "https://www.sciencedirect.com/science/article/pii/S221242092100501X                                                                 1\n",
      "https://ntrs.nasa.gov/citations/20220010955                                                                                         1\n",
      "https://gitlab.grc.nasa.gov/zyahn/titan-clouds-project                                                                              1\n",
      "dtype: int64\n",
      "Department\n",
      "Department of Energy                       178\n",
      "Department of Health and Human Services    157\n",
      "Department of Commerce                      49\n",
      "Department of Homeland Security             41\n",
      "Department of Veterans Affairs              40\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for col in data.columns:\n",
    "    print(data.groupby(col, dropna=False).size().sort_values(ascending=False, na_position='first').head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
